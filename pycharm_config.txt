看ctc解码的时候的finetune:

--config-dir
examples/hubert/config/finetune
--config-name
base_10h
task.data=/data/ygr/small20
task.label_dir=/data/ygr/small20
task.labels=["ltr"]
dataset.num_workers=6
dataset.skip_invalid_size_inputs_valid_test=true
model.w2v_path=/mnt/lustre/sjtu/home/gry10/fairseq/hubert_base_ls960.pt
model.mask_prob=0.65
dataset.validate_after_updates=0
dataset.validate_interval=1
checkpoint.save_dir=/data/ygr/small20/chel
distributed_training.distributed_world_size=1
optimization.update_freq=[8]
optimization.lr=[0.00003]
optimization.max_update=50000
lr_scheduler.warmup_steps=8000
lr_scheduler.hold_steps=32000
lr_scheduler.decay_steps=40000

normal finetune:

--config-dir
examples/hubert/config/finetune
--config-name
base_10h
task.data=/data/ygr/small20
task.label_dir=/data/ygr/small20
task.labels=["ltr"]
dataset.num_workers=6
dataset.skip_invalid_size_inputs_valid_test=true
dataset.validate_after_updates=0
dataset.validate_interval=1
model.w2v_path=/mnt/lustre/sjtu/home/gry10/fairseq/pretrain_yinsu_ck/checkpoint40.pt
model.mask_prob=0.65
checkpoint.save_dir=/data/ygr/small20/chel
distributed_training.distributed_world_size=1
optimization.update_freq=[8]
optimization.lr=[0.00003]
optimization.max_update=80000
lr_scheduler.warmup_steps=8000
lr_scheduler.hold_steps=32000
lr_scheduler.decay_steps=40000

fbank finetune:

--config-dir
examples/hubert/config/finetune
--config-name
base_10h
task.data=/data/ygr/librispeech/npyfiles
task.label_dir=/data/ygr/k500
task.labels=["ltr"]
dataset.train_subset=train_clean_100
dataset.valid_subset=dev_other
dataset.num_workers=6
dataset.skip_invalid_size_inputs_valid_test=true
dataset.validate_after_updates=0
dataset.validate_interval=1
model.w2v_path=/mnt/lustre/sjtu/home/gry10/fairseq/pretrain_fbank_cmvn_ck/checkpoint20.pt
model.mask_prob=0.65
checkpoint.save_dir=/mnt/lustre/sjtu/home/gry10/fairseq/finetune_fbank/checkpoint/fine20
distributed_training.distributed_world_size=1
optimization.update_freq=[8]
optimization.lr=[0.00003]
optimization.max_update=80000
lr_scheduler.warmup_steps=8000
lr_scheduler.hold_steps=32000
lr_scheduler.decay_steps=40000
task._name=hubert_fbank_pretraining
dataset.max_tokens=8750
task.sample_rate=100



fbank pretrain:

--config-dir examples/hubert/config/pretrain
--config-name hubert_base_librispeech
task.data=/data/ygr/librispeech/npyfiles
task.label_dir=/data/ygr/k500
task.labels=["km"]
dataset.valid_subset=dev_clean
model.label_rate=50
distributed_training.distributed_world_size=1
optimization.update_freq=[8]
checkpoint.save_interval=40
checkpoint.keep_interval_updates=-1
checkpoint.no_epoch_checkpoints=false
checkpoint.save_dir=/mnt/lustre/sjtu/home/gry10/fairseq/pretrain_fbank_ck_debug
dataset.max_tokens=8750
model._name=hubert_fbank_offline
task._name=hubert_fbank_pretraining
task.sample_rate=100

normal pretrain:

--config-dir examples/hubert/config/pretrain
--config-name hubert_base_librispeech
task.data=/data/ygr/shu
task.label_dir=/data/ygr/k500
task.labels=["km"]
model.label_rate=50
distributed_training.distributed_world_size=1
optimization.update_freq=[8]
checkpoint.save_interval=40
checkpoint.keep_interval_updates=-1
checkpoint.no_epoch_checkpoints=false
checkpoint.save_dir=/mnt/lustre/sjtu/home/gry10/fairseq/pretrain_debug_ck

normal pretrain with no mask:

--config-dir examples/hubert/config/pretrain
--config-name hubert_base_librispeech
task.data=/data/ygr/shu
task.label_dir=/data/ygr/k500
task.labels=["km"]
model.label_rate=50
distributed_training.distributed_world_size=1
optimization.update_freq=[8]
checkpoint.save_interval=40
checkpoint.keep_interval_updates=-1
checkpoint.no_epoch_checkpoints=false
checkpoint.save_dir=/mnt/lustre/sjtu/home/gry10/fairseq/pretrain_ck
model.mask=false
criterion.pred_masked_weight=0
criterion.pred_nomask_weight=1

normal small pretrain:

--config-dir examples/hubert/config/pretrain
--config-name hubert_base_librispeech
task.data=/data/ygr/small20
task.label_dir=/data/ygr/small20
task.labels=["km"]
model.label_rate=50
distributed_training.distributed_world_size=1
optimization.update_freq=[8]
checkpoint.save_interval=40
checkpoint.keep_interval_updates=-1
checkpoint.no_epoch_checkpoints=false
checkpoint.save_dir=/data/ygr/small20/che


pretrain new criterion:

--config-dir examples/hubert/config/pretrain
--config-name hubert_base_librispeech
task.data=/data/ygr/shu
task.label_dir=/data/ygr/k500
task.labels=["km"]
model.label_rate=50
distributed_training.distributed_world_size=1
optimization.update_freq=[8]
checkpoint.save_interval=40
checkpoint.keep_interval_updates=-1
checkpoint.no_epoch_checkpoints=false
checkpoint.save_dir=/mnt/lustre/sjtu/home/gry10/fairseq/pretrain_debug_ck
criterion._name=hubertce
model._name=hubertce


phoneme_validate:

--config-dir examples/hubert/config/validate
--config-name validate
task.data=/data/ygr/data2vec_jt
task.label_dir=/data/ygr/data2vec_jt
task.labels=["phn"]
dataset.train_subset=train_960
dataset.valid_subset=dev_clean
model.label_rate=50
distributed_training.distributed_world_size=1
optimization.update_freq=[8]
checkpoint.save_interval=5
checkpoint.keep_interval_updates=-1
checkpoint.no_epoch_checkpoints=false
checkpoint.save_dir=/mnt/lustre/sjtu/home/gry10/fairseq/yinsu_validate_ck

